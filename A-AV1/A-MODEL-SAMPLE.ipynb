{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mithi/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from helpers import BirdsEye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters \n",
    "BATCH_SIZE = 64\n",
    "NUMBER_OF_EPOCHS = 20\n",
    "VALIDATION_SIZE = 0.10\n",
    "OPTIMIZER_TYPE = \"adam\"\n",
    "LOSS_TYPE = \"mse\"\n",
    "MODELH5_NAME = \"./misc/model2.h5\"\n",
    "MODELJSON_NAME = \"./misc/model2.json\"\n",
    "INPUT_SHAPE = (66, 200, 3)\n",
    "\n",
    "# For warping the image\n",
    "SOURCE_POINTS = [(0, 43), (130, 15), (190, 15), (320, 43)]\n",
    "DEST_POINTS = [(130, 50), (130, 10), (190, 10), (190, 50)]\n",
    "BIRDS_EYE = BirdsEye(SOURCE_POINTS, DEST_POINTS)\n",
    "\n",
    "# For cropping the image\n",
    "YSTART, YSTOP = 100, 166\n",
    "XSTART, XSTOP = 50, 250\n",
    "\n",
    "CSV_FILE = \"./samples/logs.csv\"\n",
    "IMAGE_DIR = \"./samples/many-images/\"\n",
    "\n",
    "DATA = pd.read_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steer):\n",
    "    if np.random.random() > 0.5:\n",
    "        return np.fliplr(image), -steer\n",
    "    else:\n",
    "        return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(x, data):\n",
    "    \n",
    "    i = data.index[x]\n",
    "    steer =  data['STEER'][i]\n",
    "\n",
    "    unprocessed_img = mpimg.imread(IMAGE_DIR + data['NAME'][i])\n",
    "    cropped_img = unprocessed_img[YSTART:YSTOP, :, :]\n",
    "    sky_img = BIRDS_EYE.skyview(cropped_img)\n",
    "    img = sky_img[:, XSTART:XSTOP]\n",
    "    cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    return random_flip(img, steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data, batch_size):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        SIZE = len(data)\n",
    "        data.sample(frac=1) #shuffle\n",
    "\n",
    "        for start in range(0, SIZE, batch_size):\n",
    "            images, steers = [], []\n",
    "\n",
    "            for i in range(start, start + batch_size):\n",
    "                if i < SIZE:\n",
    "                    image, steer = get_processed_data(i, data)\n",
    "                    steers.append(steer)\n",
    "                    images.append(image)\n",
    "\n",
    "            yield (np.array(images), np.array(steers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modified_nvidia_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = OPTIMIZER_TYPE, loss = LOSS_TYPE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 98, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 47, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 22, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 20, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 18, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 18, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_modified_nvidia_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/20\n",
      "3251/3251 [==============================] - 60s - loss: 44.9017 - val_loss: 44.2037\n",
      "Epoch 2/20\n",
      "3251/3251 [==============================] - 65s - loss: 35.9989 - val_loss: 39.0044\n",
      "Epoch 3/20\n",
      "3251/3251 [==============================] - 50s - loss: 36.2947 - val_loss: 32.7405\n",
      "Epoch 4/20\n",
      "3251/3251 [==============================] - 52s - loss: 34.2236 - val_loss: 33.7516\n",
      "Epoch 5/20\n",
      "3251/3251 [==============================] - 50s - loss: 33.9835 - val_loss: 32.2932\n",
      "Epoch 6/20\n",
      "3251/3251 [==============================] - 91s - loss: 32.1892 - val_loss: 31.9231\n",
      "Epoch 7/20\n",
      "3251/3251 [==============================] - 98s - loss: 32.5571 - val_loss: 33.4141\n",
      "Epoch 8/20\n",
      "3251/3251 [==============================] - 86s - loss: 31.9877 - val_loss: 31.2849\n",
      "Epoch 9/20\n",
      "3251/3251 [==============================] - 46s - loss: 31.4823 - val_loss: 31.1150\n",
      "Epoch 10/20\n",
      "3251/3251 [==============================] - 44s - loss: 32.2189 - val_loss: 30.2521\n",
      "Epoch 11/20\n",
      "3251/3251 [==============================] - 55s - loss: 31.7365 - val_loss: 32.3157\n",
      "Epoch 12/20\n",
      "3251/3251 [==============================] - 53s - loss: 30.6938 - val_loss: 32.1652\n",
      "Epoch 13/20\n",
      "3251/3251 [==============================] - 42s - loss: 30.2499 - val_loss: 30.8404\n",
      "Epoch 14/20\n",
      "3251/3251 [==============================] - 57s - loss: 31.2165 - val_loss: 30.4870\n",
      "Epoch 15/20\n",
      "3251/3251 [==============================] - 55s - loss: 31.2913 - val_loss: 31.3150\n",
      "Epoch 16/20\n",
      "3251/3251 [==============================] - 57s - loss: 31.2035 - val_loss: 31.0720\n",
      "Epoch 17/20\n",
      "3251/3251 [==============================] - 43s - loss: 30.3705 - val_loss: 30.8735\n",
      "Epoch 18/20\n",
      "3251/3251 [==============================] - 42s - loss: 30.1073 - val_loss: 31.1873\n",
      "Epoch 19/20\n",
      "3251/3251 [==============================] - 36s - loss: 29.6678 - val_loss: 30.8149\n",
      "Epoch 20/20\n",
      "3251/3251 [==============================] - 44s - loss: 29.9493 - val_loss: 30.9683\n",
      "...Model trained.\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "\n",
    "TRAINING_DATA, VALIDATION_DATA = train_test_split(DATA, test_size=VALIDATION_SIZE)\n",
    "TOTAL_TRAIN_DATA = len(TRAINING_DATA)\n",
    "TOTAL_VALID_DATA = len(VALIDATION_DATA)\n",
    "\n",
    "# print(TOTAL_TRAIN_DATA, TOTAL_VALID_DATA)\n",
    "# TRAINING_DATA.head()\n",
    "# VALIDATION_DATA.head()\n",
    "\n",
    "training_generator = generate_samples(TRAINING_DATA, batch_size=BATCH_SIZE)\n",
    "validation_generator = generate_samples(VALIDATION_DATA, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.fit_generator(training_generator,\n",
    "    samples_per_epoch=TOTAL_TRAIN_DATA,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=TOTAL_VALID_DATA,\n",
    "    nb_epoch=NUMBER_OF_EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "print('...Model trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "...Model Saved.\n"
     ]
    }
   ],
   "source": [
    "print('Saving model...')\n",
    "\n",
    "model.save(MODELH5_NAME)\n",
    "\n",
    "with open(MODELJSON_NAME, \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "\n",
    "print(\"...Model Saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
