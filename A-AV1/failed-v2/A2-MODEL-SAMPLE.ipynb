{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mithi/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from helpers import BirdsEye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters \n",
    "BATCH_SIZE = 256\n",
    "NUMBER_OF_EPOCHS = 20\n",
    "VALIDATION_SIZE = 0.10\n",
    "OPTIMIZER_TYPE = \"adam\"\n",
    "LOSS_TYPE = \"mse\"\n",
    "MODELH5_NAME = \"./misc/modelv2.h5\"\n",
    "MODELJSON_NAME = \"./misc/modelv2.json\"\n",
    "INPUT_SHAPE = (66, 200, 3)\n",
    "\n",
    "# For warping the image\n",
    "SOURCE_POINTS = [(0, 43), (130, 15), (190, 15), (320, 43)]\n",
    "DEST_POINTS = [(130, 50), (130, 10), (190, 10), (190, 50)]\n",
    "BIRDS_EYE = BirdsEye(SOURCE_POINTS, DEST_POINTS)\n",
    "\n",
    "# For cropping the image\n",
    "YSTART, YSTOP = 100, 166\n",
    "XSTART, XSTOP = 50, 250\n",
    "\n",
    "IMAGE_DIR = \"./samples/v2-images/\"\n",
    "CSV_FILE = \"./samples/logs-v2.csv\"\n",
    "DATA = pd.read_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Don't run if there's nothing wrong in your csv files\n",
    "# Delete rows in logs that do not have existing image file in directory (IE corrupted log file)\n",
    "\n",
    "OLD_CSV_FILE = \"./samples/logs-v2-original.csv\"\n",
    "\n",
    "DATA = pd.read_csv(OLD_CSV_FILE)\n",
    "print(\"number of rows:\", len(DATA))\n",
    "print(DATA.tail())\n",
    "\n",
    "for i in range(0, len(DATA)):\n",
    "    image_name = DATA['NAME'][i]\n",
    "    image_path = IMAGE_DIR + image_name\n",
    "    try:\n",
    "        unprocessed_img = mpimg.imread(image_path)\n",
    "        print(image_name, \"exists.\")\n",
    "    except:\n",
    "        print(\"delete:\", i, \"name:\", image_name)\n",
    "        DATA = DATA.drop([i])\n",
    "\n",
    "print(\"Cleaned data:\", len(DATA))\n",
    "\n",
    "NEW_CSV_FILE = \"./samples/logs-v2.csv\"\n",
    "DATA.to_csv(NEW_CSV_FILE, index=False, encoding='utf8')\n",
    "\n",
    "DATA = pd.read_csv(NEW_CSV_FILE)\n",
    "print(\"number of rows:\", len(DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steer):\n",
    "    if np.random.random() > 0.5:\n",
    "        return np.fliplr(image), -steer\n",
    "    else:\n",
    "        return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(x, data):\n",
    "    \n",
    "    i = data.index[x]\n",
    "    steer =  data['STEER'][i]\n",
    "    image_path = IMAGE_DIR + data['NAME'][i]\n",
    "    unprocessed_img = mpimg.imread(image_path)\n",
    "    cropped_img = unprocessed_img[YSTART:YSTOP, :, :]\n",
    "    sky_img = BIRDS_EYE.skyview(cropped_img)\n",
    "    img = sky_img[:, XSTART:XSTOP]\n",
    "    cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    return random_flip(img, steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data, batch_size):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        SIZE = len(data)\n",
    "        data.sample(frac=1) #shuffle\n",
    "\n",
    "        for start in range(0, SIZE, batch_size):\n",
    "            images, steers = [], []\n",
    "\n",
    "            for i in range(start, start + batch_size):\n",
    "                if i < SIZE:\n",
    "                    image, steer = get_processed_data(i, data)\n",
    "                    steers.append(steer)\n",
    "                    images.append(image)\n",
    "\n",
    "            yield (np.array(images), np.array(steers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modified_nvidia_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = OPTIMIZER_TYPE, loss = LOSS_TYPE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 98, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 47, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 22, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 20, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 18, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 18, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_modified_nvidia_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/20\n",
      "21028/21028 [==============================] - 401s - loss: 80.0627 - val_loss: 72.3311\n",
      "Epoch 2/20\n",
      "21028/21028 [==============================] - 305s - loss: 71.2827 - val_loss: 70.5750\n",
      "Epoch 3/20\n",
      "21028/21028 [==============================] - 462s - loss: 69.7131 - val_loss: 70.6674\n",
      "Epoch 4/20\n",
      "21028/21028 [==============================] - 466s - loss: 68.7946 - val_loss: 69.9596\n",
      "Epoch 5/20\n",
      "21028/21028 [==============================] - 387s - loss: 68.7463 - val_loss: 70.4908\n",
      "Epoch 6/20\n",
      "21028/21028 [==============================] - 205s - loss: 68.3200 - val_loss: 66.9899\n",
      "Epoch 7/20\n",
      "21028/21028 [==============================] - 205s - loss: 67.6626 - val_loss: 67.6986\n",
      "Epoch 8/20\n",
      "21028/21028 [==============================] - 206s - loss: 67.5285 - val_loss: 67.0844\n",
      "Epoch 9/20\n",
      "21028/21028 [==============================] - 205s - loss: 67.1530 - val_loss: 67.4116\n",
      "Epoch 10/20\n",
      "21028/21028 [==============================] - 210s - loss: 66.7750 - val_loss: 68.3768\n",
      "Epoch 11/20\n",
      "21028/21028 [==============================] - 214s - loss: 66.8378 - val_loss: 67.6643\n",
      "Epoch 12/20\n",
      "21028/21028 [==============================] - 213s - loss: 66.6452 - val_loss: 66.4128\n",
      "Epoch 13/20\n",
      "21028/21028 [==============================] - 212s - loss: 66.4909 - val_loss: 66.7136\n",
      "Epoch 14/20\n",
      "21028/21028 [==============================] - 213s - loss: 66.1481 - val_loss: 65.4549\n",
      "Epoch 15/20\n",
      "21028/21028 [==============================] - 1633s - loss: 66.2193 - val_loss: 66.1478\n",
      "Epoch 16/20\n",
      "21028/21028 [==============================] - 205s - loss: 66.1273 - val_loss: 66.4289\n",
      "Epoch 17/20\n",
      "21028/21028 [==============================] - 216s - loss: 65.2065 - val_loss: 65.9818\n",
      "Epoch 18/20\n",
      "21028/21028 [==============================] - 231s - loss: 65.3771 - val_loss: 65.5732\n",
      "Epoch 19/20\n",
      "21028/21028 [==============================] - 332s - loss: 65.1002 - val_loss: 65.6171\n",
      "Epoch 20/20\n",
      "21028/21028 [==============================] - 304s - loss: 65.0393 - val_loss: 65.6280\n",
      "...Model trained.\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "\n",
    "TRAINING_DATA, VALIDATION_DATA = train_test_split(DATA, test_size=VALIDATION_SIZE)\n",
    "TOTAL_TRAIN_DATA = len(TRAINING_DATA)\n",
    "TOTAL_VALID_DATA = len(VALIDATION_DATA)\n",
    "\n",
    "training_generator = generate_samples(TRAINING_DATA, batch_size=BATCH_SIZE)\n",
    "validation_generator = generate_samples(VALIDATION_DATA, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.fit_generator(training_generator,\n",
    "    samples_per_epoch=TOTAL_TRAIN_DATA,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=TOTAL_VALID_DATA,\n",
    "    nb_epoch=NUMBER_OF_EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "print('...Model trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "...Model Saved.\n"
     ]
    }
   ],
   "source": [
    "print('Saving model...')\n",
    "\n",
    "model.save(MODELH5_NAME)\n",
    "\n",
    "with open(MODELJSON_NAME, \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "\n",
    "print(\"...Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
