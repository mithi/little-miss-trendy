{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mithi/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from utils import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "csv filepath:  ./road-images/red.csv\n",
      "number of images:  8949\n",
      "sample data: \n",
      "                                                NAME  STEER\n",
      "0  ./road-images/red-flat/eagle_2018_09_14_20_29_...    0.0\n",
      "1  ./road-images/red-flat/eagle_2018_09_14_20_29_...    0.0\n",
      "2  ./road-images/red-flat/eagle_2018_09_14_20_29_...    0.0\n",
      "3  ./road-images/red-flat/eagle_2018_09_14_20_29_...    0.0\n",
      "4  ./road-images/red-flat/eagle_2018_09_14_20_29_...    0.0\n",
      "\n",
      "=========\n",
      "\n",
      "csv filepath:  ./road-images/green.csv\n",
      "number of images:  8824\n",
      "sample data: \n",
      "                                                NAME  STEER\n",
      "0  ./road-images/green-flat/eagle_2018_09_14_20_2...    0.0\n",
      "1  ./road-images/green-flat/eagle_2018_09_14_20_2...    0.0\n",
      "2  ./road-images/green-flat/eagle_2018_09_14_20_2...    0.0\n",
      "3  ./road-images/green-flat/eagle_2018_09_14_20_2...    0.0\n",
      "4  ./road-images/green-flat/eagle_2018_09_14_20_2...    0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters \n",
    "BATCH_SIZE = 128\n",
    "NUMBER_OF_EPOCHS = 5\n",
    "VALIDATION_SIZE = 0.15\n",
    "OPTIMIZER_TYPE = \"adam\"\n",
    "LOSS_TYPE = \"mse\"\n",
    "INPUT_H, INPUT_W = 75, 200\n",
    "INPUT_SHAPE = (INPUT_H, INPUT_W, 3)\n",
    "# Crop parameters\n",
    "YSTART = 110\n",
    "YSTOP = 230\n",
    "\n",
    "print(\"=========\")\n",
    "left_red_frame = DataFrame(\"./road-images/red.csv\")\n",
    "print(\"=========\")\n",
    "right_green_frame = DataFrame(\"./road-images/green.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steer):\n",
    "    if np.random.random() > 0.5:\n",
    "        return np.fliplr(image), -steer\n",
    "    else:\n",
    "        return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(x, data):\n",
    "    \n",
    "    i = data.index[x]\n",
    "    steer =  data['STEER'][i]\n",
    "    img = mpimg.imread(data['NAME'][i])\n",
    "    img = img[YSTART:YSTOP, :, :]\n",
    "    img = cv2.resize(img, (INPUT_W, INPUT_H), cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    return random_flip(img, steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data, batch_size):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        SIZE = len(data)\n",
    "        data.sample(frac=1)\n",
    "\n",
    "        for start in range(0, SIZE, batch_size):\n",
    "            images, steers = [], []\n",
    "\n",
    "            for i in range(start, start + batch_size):\n",
    "                if i < SIZE:\n",
    "                    image, steer = get_processed_data(i, data)\n",
    "                    steers.append(steer)\n",
    "                    images.append(image)\n",
    "\n",
    "            yield (np.array(images), np.array(steers))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modified_nvidia_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = OPTIMIZER_TYPE, loss = LOSS_TYPE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, modelh5_name, modeljson_name):\n",
    "    \n",
    "    print('summary of model:')\n",
    "    model.summary()\n",
    "    \n",
    "    print('Training model...')\n",
    "\n",
    "    TRAINING_DATA, VALIDATION_DATA = train_test_split(data, test_size=VALIDATION_SIZE)\n",
    "    TOTAL_TRAIN_DATA = len(TRAINING_DATA)\n",
    "    TOTAL_VALID_DATA = len(VALIDATION_DATA)\n",
    "\n",
    "    training_generator = generate_samples(TRAINING_DATA, batch_size=BATCH_SIZE)\n",
    "    validation_generator = generate_samples(VALIDATION_DATA, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model.fit_generator(training_generator,\n",
    "        samples_per_epoch=TOTAL_TRAIN_DATA,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=TOTAL_VALID_DATA,\n",
    "        nb_epoch=NUMBER_OF_EPOCHS,\n",
    "        verbose=1)\n",
    "\n",
    "    print('...Model trained.')\n",
    "    \n",
    "    print('Saving model...')\n",
    "    \n",
    "    model.save(modelh5_name)\n",
    "\n",
    "    with open(modeljson_name, \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "\n",
    "    print(\"...Model Saved.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_red_model = build_modified_nvidia_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of model:\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 75, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 36, 98, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 47, 36)    21636       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 6, 22, 48)     43248       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 4, 20, 64)     27712       convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 2, 18, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2, 18, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2304)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           230500      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 367,419\n",
      "Trainable params: 367,419\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "7606/7606 [==============================] - 132s - loss: 39.5101 - val_loss: 39.7286\n",
      "Epoch 2/5\n",
      "7606/7606 [==============================] - 107s - loss: 33.1237 - val_loss: 37.1680\n",
      "Epoch 3/5\n",
      "7606/7606 [==============================] - 147s - loss: 32.0510 - val_loss: 37.0056\n",
      "Epoch 4/5\n",
      "7606/7606 [==============================] - 151s - loss: 31.3206 - val_loss: 37.7525\n",
      "Epoch 5/5\n",
      "7606/7606 [==============================] - 148s - loss: 30.5689 - val_loss: 36.9172\n",
      "...Model trained.\n",
      "Saving model...\n",
      "...Model Saved.\n"
     ]
    }
   ],
   "source": [
    "left_red_model = train_model(left_red_model, left_red_frame.data, \"./models/left_red.h5\", \"./models/left_red.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of model:\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_3 (Lambda)                (None, 75, 200, 3)    0           lambda_input_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 36, 98, 24)    1824        lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 16, 47, 36)    21636       convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 6, 22, 48)     43248       convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 4, 20, 64)     27712       convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 2, 18, 64)     36928       convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 2, 18, 64)     0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 2304)          0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 100)           230500      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            5050        dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 10)            510         dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             11          dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 367,419\n",
      "Trainable params: 367,419\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 103s - loss: 43.7872 - val_loss: 38.9607\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 96s - loss: 35.1925 - val_loss: 37.9546\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 96s - loss: 34.2665 - val_loss: 36.0543\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 97s - loss: 33.5209 - val_loss: 35.4801\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 97s - loss: 33.3294 - val_loss: 34.5438\n",
      "...Model trained.\n",
      "Saving model...\n",
      "...Model Saved.\n"
     ]
    }
   ],
   "source": [
    "right_green_model = build_modified_nvidia_model()\n",
    "right_green_model = train_model(right_green_model, right_green_frame.data, \"./models/right_green.h5\", \"./models/right_green.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
